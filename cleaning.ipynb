{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import ast\n",
    "from fuzzywuzzy import process\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games= pd.read_csv('all_teams.csv')\n",
    "df_posts = pd.read_csv('hockey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get posts in target date range and language\n",
    "after = datetime.date(2023, 10, 10)\n",
    "before = datetime.date(2024, 4, 18)\n",
    "df_posts[\"creation_time\"] = pd.to_datetime(df_posts[\"creation_time\"], utc=True)\n",
    "df_posts = df_posts[(df_posts['creation_time'].dt.date >= after) & (df_posts['creation_time'].dt.date <= before)]\n",
    "df_posts = df_posts.sort_values(by=\"creation_time\")\n",
    "df_posts = df_posts[df_posts[\"lang\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine caption and hashtags to use to look for teams\n",
    "df_posts[\"hashtags\"] = df_posts[\"hashtags\"].fillna(\" \")\n",
    "df_posts[\"text\"] = df_posts[\"text\"].fillna(\" \")\n",
    "\n",
    "df_posts[\"combined\"] = df_posts[\"hashtags\"] + \" \" + df_posts[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games = df_games[df_games['situation'] == 'all']\n",
    "df_games = df_games[df_games['season'] == 2023]\n",
    "df_games['gameDate'] = pd.to_datetime(df_games['gameDate'].astype(str), format='%Y%m%d')\n",
    "df_games['gameDate'] = pd.to_datetime(df_games['gameDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_combined(combined_field):\n",
    "    try:\n",
    "        # Try parsing as a list\n",
    "        return ' '.join(ast.literal_eval(combined_field))\n",
    "    except (ValueError, SyntaxError):\n",
    "        # If it fails, treat it as a plain string\n",
    "        return combined_field.replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"'\", \"\").replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_mapping = {\n",
    "    \"ANA\": \"Anaheim Ducks\",\n",
    "    \"ARI\": \"Arizona Coyotes\",\n",
    "    \"BOS\": \"Boston Bruins\",\n",
    "    \"BUF\": \"Buffalo Sabres\",\n",
    "    \"CAR\": \"Carolina Hurricanes\",\n",
    "    \"CBJ\": \"Columbus Blue Jackets\",\n",
    "    \"CGY\": \"Calgary Flames\",\n",
    "    \"CHI\": \"Chicago Blackhawks\",\n",
    "    \"COL\": \"Colorado Avalanche\",\n",
    "    \"DAL\": \"Dallas Stars\",\n",
    "    \"DET\": \"Detroit Red Wings\",\n",
    "    \"EDM\": \"Edmonton Oilers\",\n",
    "    \"FLA\": \"Florida Panthers\",\n",
    "    \"LAK\": \"Los Angeles Kings\",\n",
    "    \"MIN\": \"Minnesota Wild\",\n",
    "    \"MTL\": \"Montreal Canadiens\",\n",
    "    \"NJD\": \"New Jersey Devils\",\n",
    "    \"NSH\": \"Nashville Predators\",\n",
    "    \"NYI\": \"New York Islanders\",\n",
    "    \"NYR\": \"New York Rangers\",\n",
    "    \"OTT\": \"Ottawa Senators\",\n",
    "    \"PHI\": \"Philadelphia Flyers\",\n",
    "    \"PIT\": \"Pittsburgh Penguins\",\n",
    "    \"SEA\": \"Seattle Kraken\",\n",
    "    \"SJS\": \"San Jose Sharks\",\n",
    "    \"STL\": \"St. Louis Blues\",\n",
    "    \"TBL\": \"Tampa Bay Lightning\",\n",
    "    \"TOR\": \"Toronto Maple Leafs\",\n",
    "    \"VAN\": \"Vancouver Canucks\",\n",
    "    \"VGK\": \"Vegas Golden Knights\",\n",
    "    \"WPG\": \"Winnipeg Jets\",\n",
    "    \"WSH\": \"Washington Capitals\"\n",
    "}\n",
    "\n",
    "city_mapping = {\n",
    "    \"ANA\": \"Anaheim\",\n",
    "    \"ARI\": \"Arizona\",\n",
    "    \"BOS\": \"Boston\",\n",
    "    \"BUF\": \"Buffalo\",\n",
    "    \"CAR\": \"Carolina\",\n",
    "    \"CBJ\": \"Columbus\",\n",
    "    \"CGY\": \"Calgary\",\n",
    "    \"CHI\": \"Chicago\",\n",
    "    \"COL\": \"Colorado\",\n",
    "    \"DAL\": \"Dallas\",\n",
    "    \"DET\": \"Detroit\",\n",
    "    \"EDM\": \"Edmonton\",\n",
    "    \"FLA\": \"Florida\",\n",
    "    \"LAK\": \"Los Angeles\",\n",
    "    \"MIN\": \"Minnesota\",\n",
    "    \"MTL\": \"Montreal\",\n",
    "    \"NJD\": \"New Jersey\",\n",
    "    \"NSH\": \"Nashville\",\n",
    "    \"NYI\": \"New York\",\n",
    "    \"NYR\": \"New York\",\n",
    "    \"OTT\": \"Ottawa\",\n",
    "    \"PHI\": \"Philadelphia\",\n",
    "    \"PIT\": \"Pittsburgh\",\n",
    "    \"SEA\": \"Seattle\",\n",
    "    \"SJS\": \"San Jose\",\n",
    "    \"STL\": \"St. Louis\",\n",
    "    \"TBL\": \"Tampa Bay\",\n",
    "    \"TOR\": \"Toronto\",\n",
    "    \"VAN\": \"Vancouver\",\n",
    "    \"VGK\": \"Vegas\",\n",
    "    \"WPG\": \"Winnipeg\",\n",
    "    \"WSH\": \"Washington\"\n",
    "}\n",
    "\n",
    "name_mapping = {\n",
    "    \"ANA\": \"Ducks\",\n",
    "    \"ARI\": \"Coyotes\",\n",
    "    \"BOS\": \"Bruins\",\n",
    "    \"BUF\": \"Sabres\",\n",
    "    \"CAR\": \"Hurricanes\",\n",
    "    \"CBJ\": \"Blue Jackets\",\n",
    "    \"CGY\": \"Flames\",\n",
    "    \"CHI\": \"Blackhawks\",\n",
    "    \"COL\": \"Avalanche\",\n",
    "    \"DAL\": \"Stars\",\n",
    "    \"DET\": \"Red Wings\",\n",
    "    \"EDM\": \"Oilers\",\n",
    "    \"FLA\": \"Panthers\",\n",
    "    \"LAK\": \"Kings\",\n",
    "    \"MIN\": \"Wild\",\n",
    "    \"MTL\": \"Canadiens\",\n",
    "    \"NJD\": \"Devils\",\n",
    "    \"NSH\": \"Predators\",\n",
    "    \"NYI\": \"Islanders\",\n",
    "    \"NYR\": \"Rangers\",\n",
    "    \"OTT\": \"Senators\",\n",
    "    \"PHI\": \"Flyers\",\n",
    "    \"PIT\": \"Penguins\",\n",
    "    \"SEA\": \"Kraken\",\n",
    "    \"SJS\": \"Sharks\",\n",
    "    \"STL\": \"Blues\",\n",
    "    \"TBL\": \"Lightning\",\n",
    "    \"TOR\": \"Maple Leafs\",\n",
    "    \"VAN\": \"Canucks\",\n",
    "    \"VGK\": \"Golden Knights\",\n",
    "    \"WPG\": \"Jets\",\n",
    "    \"WSH\": \"Capitals\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games['team_full_name'] = df_games['team'].map(team_mapping)\n",
    "df_games['city'] = df_games['team'].map(city_mapping)\n",
    "df_games['name'] = df_games['team'].map(name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['lowered'] = df_posts['combined'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_post(post, games):\n",
    "    # Match games by date\n",
    "    post_date = post['creation_time'].date()\n",
    "    # Create date range for the day before, same day, and day after\n",
    "    date_range = [\n",
    "        pd.Timestamp(post_date - pd.Timedelta(days=1)),  # Day before\n",
    "        pd.Timestamp(post_date),                        # Same day\n",
    "        pd.Timestamp(post_date + pd.Timedelta(days=1))  # Day after\n",
    "    ]\n",
    "\n",
    "    # Filter games by date range\n",
    "    nearby_games = games[games['gameDate'].isin(date_range)]\n",
    "    \n",
    "    # Extract keywords from the post\n",
    "    post_keywords = parse_combined(post['lowered'])\n",
    "    \n",
    "    # Match team names\n",
    "    for _, game in nearby_games.iterrows():\n",
    "        if game['team'] in post_keywords:\n",
    "            return game['gameId']\n",
    "        team_match = process.extractOne(game['city'].lower(), [post_keywords])\n",
    "        team_match2 = process.extractOne(game['team_full_name'].lower(), [post_keywords])\n",
    "        team_match3 = process.extractOne(game['name'].lower(), [post_keywords])\n",
    "\n",
    "        if team_match and team_match[1] > 55:  # Adjust threshold as needed\n",
    "            return game['gameId']\n",
    "        if team_match2 and team_match2[1] > 55:\n",
    "            return game['gameId']\n",
    "        if team_match3 and team_match3[1] > 55:\n",
    "            return game['gameId']\n",
    "    \n",
    "    return \"No Game\"  \n",
    "\n",
    "# Apply the classification function to posts\n",
    "df_posts['game'] = df_posts.apply(lambda post: classify_post(post, df_games), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = df_posts[df_posts['game'] != 'No Game']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the teams involved in a game\n",
    "def get_teams(game_id, games):\n",
    "    game_info = games[games['gameId'] == game_id]\n",
    "    if game_info.empty:\n",
    "        print(f\"Game ID {game_id} not found\")\n",
    "        return \"Unknown\", \"Unknown\"\n",
    "\n",
    "    team1 = game_info.iloc[0]['playerTeam']\n",
    "    team2 = game_info.iloc[0]['opposingTeam']\n",
    "    if game_info.iloc[0][\"goalsFor\"] > game_info.iloc[0][\"goalsAgainst\"]:\n",
    "        return team1, team2\n",
    "    else:\n",
    "        return team2, team1\n",
    "\n",
    "df_posts[['winning_team', 'losing_team']] = df_posts['game'].apply(lambda game_id: get_teams(game_id, df_games)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key='YOUR_API_KEY',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text, team1, team2):\n",
    "    prompt =f\"\"\"\n",
    "    You are an expert at understanding sports fan sentiment from social media posts. Below is a post, and your task is to determine which of the following teams the poster is a fan of:{team1, team2} . \n",
    "    For each post, output the team they are a fan of. Use the abbreviation for the team. For example, MTL for the Montreal Canadiens. RETURN ONLY THE ABBREVIATION FOR THE TEAM AND NOTHING ELSE. \n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Please label the following text: '{text}'\"}\n",
    "        ]\n",
    "    )\n",
    "    label = response.choices[0].message.content\n",
    "    return label.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_team_in_post(post):\n",
    "    winning_team = post['winning_team']\n",
    "    losing_team = post['losing_team']\n",
    "    combined_text = post['lowered']\n",
    "    post_keywords = parse_combined(post['lowered'])\n",
    "    team_match = process.extractOne(city_mapping[winning_team].lower(), [post_keywords])\n",
    "    team_match2 = process.extractOne(team_mapping[winning_team].lower(), [post_keywords])\n",
    "    team_match3 = process.extractOne(name_mapping[winning_team].lower(), [post_keywords])\n",
    "    team_match4 = process.extractOne(city_mapping[losing_team].lower(), [post_keywords])\n",
    "    team_match5 = process.extractOne(team_mapping[losing_team].lower(), [post_keywords])\n",
    "    team_match6 = process.extractOne(name_mapping[losing_team].lower(), [post_keywords])\n",
    "    win = False\n",
    "    lose = False\n",
    "    if team_match and team_match[1] > 55 or team_match2 and team_match2[1] > 55 or team_match3 and team_match3[1] > 55:\n",
    "        win = True\n",
    "    \n",
    "    if team_match4 and team_match4[1] > 55 or team_match5 and team_match5[1] > 55 or team_match6 and team_match6[1] > 55:\n",
    "        lose = True\n",
    "    \n",
    "    if win and lose:\n",
    "        return label_text(combined_text, winning_team, losing_team)\n",
    "    elif win:\n",
    "        return winning_team\n",
    "    elif lose:\n",
    "        return losing_team\n",
    "\n",
    "df_posts['team_mentioned'] = df_posts.apply(check_team_in_post, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I manually checked each entry that didn't return with the correct format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_incorrect = df_use[df_use['team_mentioned'].str.len() <= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataframe is store in df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# win or loss\n",
    "df_cleaned['team_won'] = (df_cleaned['team_mentioned'] == df_cleaned['winning_team']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close game and blow out\n",
    "df_games['diff'] = df_games['goalsFor'] - df_games['goalsAgainst']\n",
    "\n",
    "games_unique = df_games[['gameId', 'diff']].drop_duplicates(subset='gameId')\n",
    "df_cleaned = df_cleaned.merge(games_unique, left_on='game', right_on='gameId')\n",
    "df_cleaned['close_game'] = (abs(df_cleaned['diff']) <= 1).astype(int)\n",
    "df_cleaned['blowout'] = (abs(df_cleaned['diff']) >=4).astype(int)\n",
    "df_cleaned.drop(columns=['diff', 'gameId'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high scoring\n",
    "df_games['totalGoals'] = df_games['goalsFor'] + df_games['goalsAgainst']\n",
    "\n",
    "games_unique = df_games[['gameId', 'totalGoals']].drop_duplicates(subset='gameId')\n",
    "df_cleaned = df_cleaned.merge(games_unique, left_on='game', right_on='gameId')\n",
    "df_cleaned['highScoring'] = (abs(df_cleaned['totalGoals']) >= 1).astype(int)\n",
    "df_cleaned.drop(columns=['totalGoals', 'gameId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above 500\n",
    "# Initialize the win count column\n",
    "df_games['win_count'] = 0\n",
    "df_games['loss_count'] = 0\n",
    "\n",
    "# Iterate through each team and calculate the cumulative win count\n",
    "for team in df_games['playerTeam'].unique():\n",
    "    team_games = df_games[df_games['playerTeam'] == team].sort_values(by='gameDate')\n",
    "    team_games['win_count'] = team_games['goalsFor'] > team_games['goalsAgainst']\n",
    "    team_games['win_count'] = team_games['win_count'].cumsum()\n",
    "    team_games['loss_count'] = team_games['goalsFor'] < team_games['goalsAgainst']\n",
    "    team_games['loss_count'] = team_games['loss_count'].cumsum()\n",
    "    df_games.loc[team_games.index, 'loss_count'] = team_games['loss_count']\n",
    "    df_games.loc[team_games.index, 'win_count'] = team_games['win_count']\n",
    "df_games['winPercentage'] = df_games['win_count'] / (df_games['win_count'] + df_games['loss_count'])\n",
    "\n",
    "games_unique = df_games[['gameId', 'winPercentage']].drop_duplicates(subset='gameId')\n",
    "df_cleaned = df_cleaned.merge(games_unique, left_on='game', right_on='gameId')\n",
    "df_cleaned['above500'] = (df_cleaned['winPercentage'] > 0.5).astype(int)\n",
    "df_cleaned.drop(columns=['winPercentage', 'gameId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days since last game\n",
    "df_games = df_games.sort_values(by='gameDate')\n",
    "df_games['daysSinceLastGame'] = df_games.groupby('playerTeam')['gameDate'].diff().dt.days\n",
    "df_games['daysSinceLastGame'] = df_games['daysSinceLastGame'].fillna(0)\n",
    "games_unique = df_games[['gameId', 'daysSinceLastGame']].drop_duplicates(subset='gameId')\n",
    "df_cleaned = df_cleaned.merge(games_unique, left_on='game', right_on='gameId')\n",
    "df_cleaned = df_cleaned.drop(columns=['gameId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# won previous game\n",
    "# Initialize the previous win column\n",
    "df_games['won_previous'] = 0\n",
    "\n",
    "# Iterate through each team and calculate if they won their previous game\n",
    "for team in df_games['playerTeam'].unique():\n",
    "    team_games = df_games[df_games['playerTeam'] == team].sort_values(by='gameDate')\n",
    "    team_games['won_previous'] = (team_games['goalsFor'].shift(1) > team_games['goalsAgainst'].shift(1)).astype(int)\n",
    "    df_games.loc[team_games.index, 'won_previous'] = team_games['won_previous']\n",
    "\n",
    "games_unique = df_games[['gameId', 'won_previous']].drop_duplicates(subset='gameId')\n",
    "df_cleaned = df_cleaned.merge(games_unique, left_on='game', right_on='gameId')\n",
    "df_cleaned.drop(columns=['gameId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season phase\n",
    "df_games['game_number'] = df_games.groupby('playerTeam').cumcount() + 1\n",
    "df_games['total_games'] = df_games.groupby('playerTeam')['game_number'].transform('max')\n",
    "\n",
    "# Determine the thresholds for early, mid, and late season\n",
    "df_games['season_phase'] = 0\n",
    "df_games.loc[df_games['game_number'] <= df_games['total_games'] / 3, 'season_phase'] = -1\n",
    "df_games.loc[df_games['game_number'] > 2 * df_games['total_games'] / 3, 'season_phase'] = 1\n",
    "games_unique = df_games[['gameId', 'season_phase']].drop_duplicates(subset='gameId')\n",
    "df_cleaned = df_cleaned.merge(games_unique, left_on='game', right_on='gameId')\n",
    "df_cleaned.drop(columns=['gameId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cleaned.to_csv('hockey_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
